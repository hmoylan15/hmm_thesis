---
title: "usda_crop"
created: 12/31/2025
updated: 1/6/2026
output: html_document
---

### Rmarkdown Description

The purpose of this Rmarkdown is to prepare the USDA crop cover data for inclusion as a predictor in my model. I have four crop cover years worth of data (2008, 2012, 2016, 2020) and I received it from here: https://www.nass.usda.gov/Research_and_Science/Cropland/Release/index.php. 

### Preparation

Loading all the packages I will need
```{r,results = "hide", message = FALSE, warning = FALSE}
library(terra)
library(tidyverse)
library(sf)
library(tools)
```

Setting the path for the .tif files.
```{r}
usda08_path <- "../input/raw/usda_crop/2008_30m_cdls/2008_30m_cdls.tif"
usda12_path <- "../input/raw/usda_crop/2012_30m_cdls/2012_30m_cdls.tif"
usda16_path <- "../input/raw/usda_crop/2016_30m_cdls/2016_30m_cdls.tif"
usda20_path <- "../input/raw/usda_crop/2020_30m_cdls/2020_30m_cdls.tif"
```

Because the crop data layer .tif files are so large, I need to clip each crop data layer to each of the 18 aquifers first, and then merge the files together.

Preparing aquifer data.
```{r}
aq_polygon <- st_read("../input/processed/aquifer_shapefiles/all_18_aquifers.shp")

# making the shapefile an sf object
sf_aq_polygon <- st_as_sf(aq_polygon, crs = 5070)

# next, I'm going to merge polygons with the same aquifer name
aq_merged <- sf_aq_polygon %>%
  group_by(AQ_NAME) %>%
  summarize(geometry = st_union(geometry), .groups = "drop")

# now, I'm going to vectorize this in a way that terra will like
aq <- vect(aq_merged)
```

Creating the identify Ag function. All cdl codes that classify as agriculture are assigned a 1, all other cdl codes are assigned 0.
```{r}
identify_ag <- function(rast) {
  cdl_codes <- c(
    1, 2, 3, 4, 5, 6, 10, 11, 12, 13, 14, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 81, 82, 83, 87, 88, 92, 111, 112, 121, 122, 123, 124, 131, 141, 142, 143, 152, 176, 190, 195, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 254
    )
  
  cdl_names <- c(
    "Corn", "Cotton", "Rice", "Sorghum", "Soybeans", "Sunflower", "Peanuts", "Tobacco", "Sweet Corn", "Pop or Orn Corn", "Mint", "Barley", "Durum Wheat", "Spring Wheat", "Winter Wheat", "Other Small Grains", "Dbl Crop WinWht/Soybeans", "Rye", "Oats", "Millet", "Speltz", "Canola", "Flaxseed", "Safflower", "Rape Seed", "Mustard", "Alfalfa", "Other Hay/Non Alfalfa", "Camelina", "Buckwheat", "Sugarbeets", "Dry Beans", "Potatoes", "Other Crops", "Sugarcane", "Sweet Potatoes", "Misc Vegs & Fruits", "Watermelons", "Onions", "Cucumbers", "Chick Peas", "Lentils", "Peas", "Tomatoes","Caneberries", "Hops", "Herbs", "Clover/Wildflowers", "Sod/Grass Seed", "Switchgrass", "Fallow/Idle Cropland", "Forest", "Shrubland", "Barren",  "Cherries", "Peaches", "Apples", "Grapes", "Christmas Trees", "Other Tree Crops", "Citrus", "Pecans", "Almonds", "Walnuts", "Pears", "Clouds/No Data", "Developed", "Water", "Wetlands", "Nonag/Undefined", "Aquaculture", "Open Water", "Perennial Ice/Snow", "Developed/Open Space", "Developed/Low Intensity", "Developed/Med Intensity", "Developed/High Intensity", "Barren", "Deciduous Forest", "Evergreen Forest", "Mixed Forest", "Shrubland", "Grassland/Pasture", "Woody Wetlands", "Herbaceous Wetlands", "Pistachios", "Triticale", "Carrots", "Asparagus", "Garlic", "Cantaloupes", "Prunes", "Olives", "Oranges", "Honeydew Melons", "Broccoli", "Avocados", "Peppers", "Pomegranates", "Nectarines", "Greens", "Plums", "Strawberries", "Squash", "Apricots", "Vetch", "Dbl Crop WinWht/Corn", "Dbl Crop Oats/Corn", "Lettuce", "Dbl Crop Triticale/Corn", "Pumpkins", "Dbl Crop Lettuce/Durum Wht", "Dbl Crop Lettuce/Cantaloupe", "Dbl Crop Lettuce/Cotton", "Dbl Crop Lettuce/Barley", "Dbl Crop Durum Wht/Sorghum", "Dbl Crop Barley/Sorghum", "Dbl Crop WinWht/Sorghum", "Dbl Crop Barley/Corn", "Dbl Crop WinWht/Cotton", "Dbl Crop Soybeans/Cotton", "Dbl Crop Soybeans/Oats", "Dbl Crop Corn/Soybeans", "Blueberries", "Cabbage", "Cauliflower", "Celery", "Radishes", "Turnips", "Eggplants", "Gourds", "Cranberries", "Dbl Crop Barley/Soybeans"
    )

  # the classify function requires from, to, becomes matrix
  ag_ranges <- matrix(c(
    1, 60, 1,
    66, 77, 1,
    195, 254, 1
    ), 
    ncol=3, 
    byrow=TRUE
    )
  
  rast_ag <- classify(rast, rcl = ag_ranges, others = 0)
  
  names(rast_ag) <- "agriculture"
    
  return(rast_ag)
}
```

Creating a function to wrangle crop data. Clip each raster to each aquifer, define ag/no ag (1/0) for each aquifer raster, and save as new raster for each of the four crop data years. Crop data has crs 5070 already.
```{r}
# establishing the directory for the .tif files
out_dir_08 <- "../input/processed/usda_crop/aquifer_clips/clips_08"
out_dir_12 <- "../input/processed/usda_crop/aquifer_clips/clips_12"
out_dir_16 <- "../input/processed/usda_crop/aquifer_clips/clips_16"
out_dir_20 <- "../input/processed/usda_crop/aquifer_clips/clips_20"

clip_ag_usda <- function(tif_path, out_dir) {
  rast <- rast(tif_path)
  
  coltab(rast) <- NULL
  
  for (i in seq_len(nrow(aq))) {
    aq_i <- aq[i]
  
    # cleaning up the aquifer names
    name <- aq_i$AQ_NAME
    name_spaced <- gsub(" ", "_", name)
    name_no_special <- gsub("[^A-Za-z0-9_]", "", name_spaced)
  
    # clipping usda crop data layer
    rast_cropped <- crop(rast, aq_i)
    rast_masked <- mask(rast_cropped, aq_i)
    rast_trimmed <- trim(rast_masked)
    
    assigned_ag <- identify_ag(rast_trimmed)
    names(assigned_ag) <- "agriculture"
    
    out_path <- file.path(out_dir, paste0(name_no_special, "_ag.tif"))
    
    coltab(assigned_ag) <- data.frame(
      value = c(0, 1),         
      red   = c(0, 255),       
      green = c(0, 255),       
      blue  = c(0, 255)
      )
    
    writeRaster(assigned_ag, out_path, overwrite = TRUE, datatype = "INT1U")
  
    message("Saved raster: ", out_path)
  }
  }
```

########################## Stopped here 12/31/2025
Using clip_ag_usda to create clipped crop data for each of the 18 aquifers.
```{r}
clip_ag_usda(tif_path = usda08_path, out_dir = out_dir_08)
```

```{r}
clip_ag_usda(tif_path = usda12_path, out_dir = out_dir_12)
```

```{r}
clip_ag_usda(tif_path = usda16_path, out_dir = out_dir_16)
```

```{r}
clip_ag_usda(tif_path = usda20_path, out_dir = out_dir_20)
```

### Merging ag/non ag Aquifer Rasters

```{r}
usda_08_tifs <- list.files("../input/processed/usda_crop/aquifer_clips/clips_08", pattern = "\\.tif$", full.names = TRUE)
usda_12_tifs <- list.files("../input/processed/usda_crop/aquifer_clips/clips_12", pattern = "\\.tif$", full.names = TRUE)
usda_16_tifs <- list.files("../input/processed/usda_crop/aquifer_clips/clips_16", pattern = "\\.tif$", full.names = TRUE)
usda_20_tifs <- list.files("../input/processed/usda_crop/aquifer_clips/clips_20", pattern = "\\.tif$", full.names = TRUE)

merge_tifs <- function(tif_files, out_dir, file_name) {
  rasters <- lapply(tif_files, rast)
  
  merged_raster <- do.call(merge, rasters)
  
  out_path <- file.path(out_dir, paste0(file_name, "_merged.tif"))
  writeRaster(merged_raster, out_path, overwrite = TRUE)
}
```

```{r}
merge_tifs(tif_files = usda_08_tifs, out_dir = out_dir_08, file_name = "usda08") 
merge_tifs(tif_files = usda_12_tifs, out_dir = out_dir_12, file_name = "usda12")
merge_tifs(tif_files = usda_16_tifs, out_dir = out_dir_16, file_name = "usda16")
merge_tifs(tif_files = usda_20_tifs, out_dir = out_dir_20, file_name = "usda20")
```

### Attribute to tt Points

I need to systematically attribute % agricultural land use to each training/testing point (sampled 1988 - 2018) from Ransom et al. 2023. I will follow the same logic as the fifth Ransom et al. 2023 metadata processing step. D0 represents the nearest decadal estimate to the sampling data, D1 the next oldest, followed by D2 for the next oldest, and D3 for the fourth oldest (if applicable). For example, I have 2008, 2012, 2016, and 2020 ag/no ag data. A well sampled in January of 2010 would use 2012 as D0, 2008 as D1. A well sampled in January of 2018 would use 2020 as D0, 2016 as D1, 2012 as D2, and 2008 as D3. This means, any sample taken before January 1, 2006 will not have a percent agricultural land use value attributed to it.

In ArcPro, I create buffers around rans_imputed (which was projected to USA_Contiguous_Albers_Equal_Area_Conic_USGS_version) and calculated mean ag (from the merged tif files which were in crs 5070 and I reprojected to the usgs crs) for each buffer for each year using zonal statistics as table. The ag stats tables were then joined back to the correctly projected rans_imputed points and converted to percentages. I exported the final data table from this step to "../input/processed/tt_data/rans_usda.csv". This work was completed within the map labeled "usda".

```{r}
# creating a lookup table to map years and column values to connect the year with the pctag column
usda_lkup <- tibble(
  year_ag = c(2008, 2012, 2016, 2020),
  col = c("ag08_pct", "ag12_pct", "ag16_pct", "ag20_pct")
)

# creating function to systematically attribute percent ag data to points sampled closest to the crop dataset year and so on
assign_dates <- function(sample_year, ag08_pct, ag12_pct, ag16_pct, ag20_pct) {
  # ensure no pctag value attributed if sample date is pre-2006
  if(sample_year < 2006) {
    return(tibble(pctag_d0 = NA_real_,
                  pctag_d1 = NA_real_,
                  pctag_d2 = NA_real_,
                  pctag_d3 = NA_real_))
  }
  
  # vectorize the ag data for the row to easily access later
  ag_row <- c(ag08_pct, ag12_pct, ag16_pct, ag20_pct)
  names(ag_row) <- usda_lkup$year_ag
  
  # find the nearest year (d0) to sample year using lookup table (takes difference between each ag year and the sample year, smallest difference will be d0_year)
  d0_year <- usda_lkup$year_ag[which.min(abs(usda_lkup$year_ag - sample_year))]
  
  # D1â€“D3 must be older than D0 (no future years), older_years are all the years older than d0 that are sorted from newest to oldest
  older_years <- sort(usda_lkup$year_ag[usda_lkup$year_ag < d0_year], decreasing = TRUE)
  
  # assign the pctag value where applicable, for d1-d3, if the length of older years is greater than or equal to 1-3 respectively, take the value of pctag in that cell
  tibble(
    pctag_d0 = ag_row[as.character(d0_year)],
    pctag_d1 = if(length(older_years) >= 1) ag_row[as.character(older_years[1])] else NA_real_,
    pctag_d2 = if(length(older_years) >= 2) ag_row[as.character(older_years[2])] else NA_real_,
    pctag_d3 = if(length(older_years) >= 3) ag_row[as.character(older_years[3])] else NA_real_
  )
}

att_pcts <- read.csv("../input/processed/tt_data/rans_usda.csv") %>%
  mutate(year = as.integer(year))

# pmap-dfr() includes mapping over rows and binding them as a dataframe
agpct_cols <- pmap_dfr(
  list(att_pcts$year, att_pcts$ag08_pct, att_pcts$ag12_pct, att_pcts$ag16_pct, att_pcts$ag20_pct),
  assign_dates
)

att_pcts1 <- bind_cols(att_pcts, agpct_cols)
```

Now, I have the ransom data AND the strategically attributed usda data. I'm going to write this data as a csv now.
```{r}
att_pcts2 <- att_pcts1 %>%
  select(-ag08_pct, -ag12_pct, -ag16_pct, -ag20_pct)

write.csv(att_pcts2, "../input/processed/tt_data/rans_usda1.csv")
```











